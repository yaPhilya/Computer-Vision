{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as L\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>classnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.avi</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.avi</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.avi</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.avi</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.avi</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename  classnum\n",
       "0  0000.avi        56\n",
       "1  0001.avi        51\n",
       "2  0002.avi        64\n",
       "3  0003.avi        23\n",
       "4  0004.avi        41"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/train_gt.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = []\n",
    "file_name = []\n",
    "for row in data.iterrows():\n",
    "    name, label = row[1]['filename'], row[1]['classnum']\n",
    "    idx = name.split('.')[0]\n",
    "    file_name.append(idx)\n",
    "    class_num.append(int(label))\n",
    "class_num = np.array(class_num)\n",
    "file_name = np.array(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.cudnn_recurrent import CuDNNLSTM\n",
    "from keras.layers.pooling import GlobalAveragePooling1D, GlobalAveragePooling2D\n",
    "from keras.layers.merge import Average\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import InputLayer, Input\n",
    "from keras.layers import Bidirectional\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7097,),\n",
       " (7097,),\n",
       " array(['4748', '4489', '5188', '2827', '4194'], dtype='<U4'),\n",
       " array([ 8, 31,  3, 32,  4]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(file_name, class_num)\n",
    "X_train.shape, y_train.shape, X_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, class_num.max() + 1)\n",
    "y_test = np_utils.to_categorical(y_test, class_num.max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1776, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_frames = []\n",
    "for name in os.listdir('data/train_converted/imgs/'):\n",
    "    num_frames.append(len(os.listdir('data/train_converted/imgs/' + name)))\n",
    "np.max(num_frames), np.min(num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAMES = 10\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SHAPE = (240, 320, 3)\n",
    "TENSOR_SHAPE = (NUM_FRAMES, ) + IMAGE_SHAPE\n",
    "TRAIN_IMGS_PATH = 'data/train_converted/imgs/'\n",
    "TRAIN_FLOW_PATH = 'data/train_converted/flow/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_generator(data, label, batch_size=32, circle=True, shuffle_data=True, shuffle_frame=True):\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle_data:\n",
    "            indices = np.random.permutation(indices)\n",
    "        for start in range(0, len(data), batch_size):\n",
    "            batch_idx = indices[start : start + batch_size]\n",
    "            y_batch = label[batch_idx]\n",
    "            X_batch = np.zeros((y_batch.shape[0],) + TENSOR_SHAPE)\n",
    "            for i, name in enumerate(data[batch_idx]):\n",
    "                for k in range(NUM_FRAMES):\n",
    "                    if not shuffle_frame:\n",
    "                        start_frame = 0\n",
    "                    else:\n",
    "                        start_frame = np.random.randint(int(0.5 * len(os.listdir(TRAIN_IMGS_PATH + name))))\n",
    "                    img = cv2.imread(TRAIN_IMGS_PATH + '{}/{}.jpg'.format(name, k + start_frame))\n",
    "                    X_batch[i, k] = preprocess_input(img)\n",
    "            yield X_batch, y_batch\n",
    "        if not circle:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_generator(names, batch_size=32):\n",
    "    for start in range(0, len(names), batch_size):\n",
    "        sub_names = names[start : start + batch_size]\n",
    "        X_batch = np.zeros((len(sub_names),) + TENSOR_SHAPE)\n",
    "        for i, name in enumerate(sub_names):\n",
    "            for k in range(NUM_FRAMES):\n",
    "                start_frame = np.random.randint(int(0.5 * len(os.listdir('data/test_converted/imgs/' + name))))\n",
    "                img = cv2.imread('data/test_converted/imgs/{}/{}.jpg'.format(name, k + start_frame))\n",
    "                X_batch[i, k] = preprocess_input(img)\n",
    "        yield X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global MODEL\n",
    "MODEL = Xception(include_top=False, weights='imagenet')\n",
    "global GRAPH\n",
    "GRAPH = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb_model(lstm_size):\n",
    "    base_model = TimeDistributed(MODEL)\n",
    "    base_model(Input(shape=TENSOR_SHAPE))\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = TimeDistributed(GlobalAveragePooling2D())(x)\n",
    "    x = Bidirectional(CuDNNLSTM(lstm_size, return_sequences=True))(x)\n",
    "    x = TimeDistributed(Dense(101, activation='softmax'))(x)\n",
    "    predictions = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layer.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    parallel_model = multi_gpu_model(model)\n",
    "    parallel_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return parallel_model, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_model, model = get_rgb_model(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = get_train_generator(X_train, y_train, batch_size=BATCH_SIZE, circle=True, shuffle_data=True, shuffle_frame=True)\n",
    "valid_generator = get_train_generator(X_test, y_test, batch_size=BATCH_SIZE, circle=True, shuffle_data=False, shuffle_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_full_path_steps = np.ceil(len(X_test) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ya-philya/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 237s 2s/step - loss: 1.5378 - acc: 0.6816 - val_loss: 2.3732 - val_acc: 0.4029\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 222s 2s/step - loss: 0.7119 - acc: 0.8194 - val_loss: 1.7455 - val_acc: 0.5232\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 217s 2s/step - loss: 0.5617 - acc: 0.8519 - val_loss: 1.3685 - val_acc: 0.6274\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 224s 2s/step - loss: 0.4767 - acc: 0.8713 - val_loss: 1.2345 - val_acc: 0.6584\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 223s 2s/step - loss: 0.3823 - acc: 0.8972 - val_loss: 1.1108 - val_acc: 0.6900\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 214s 2s/step - loss: 0.3265 - acc: 0.9099 - val_loss: 1.0676 - val_acc: 0.6820\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 224s 2s/step - loss: 0.2283 - acc: 0.9316 - val_loss: 0.9383 - val_acc: 0.7390\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 220s 2s/step - loss: 0.2330 - acc: 0.9341 - val_loss: 0.8418 - val_acc: 0.7773\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 224s 2s/step - loss: 0.1956 - acc: 0.9463 - val_loss: 0.9331 - val_acc: 0.7340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f94a8b603c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_model.fit_generator(train_generator, steps_per_epoch=100, epochs=10, validation_data=valid_generator, \n",
    "                          validation_steps=valid_full_path_steps, max_queue_size=30, workers=3, \n",
    "                          use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.layers[1].layer.layers[126:]:\n",
    "        l.trainable = True\n",
    "super_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_full_path_steps = np.ceil(len(X_test) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = get_train_generator(X_train, y_train, batch_size=BATCH_SIZE, circle=True, shuffle_data=True, shuffle_frame=True)\n",
    "valid_generator = get_train_generator(X_test, y_test, batch_size=BATCH_SIZE, circle=True, shuffle_data=False, shuffle_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ya-philya/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 446s 4s/step - loss: 0.5992 - acc: 0.8464 - val_loss: 1.5028 - val_acc: 0.6341\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 406s 4s/step - loss: 0.3478 - acc: 0.9010 - val_loss: 0.9495 - val_acc: 0.7593\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 405s 4s/step - loss: 0.2345 - acc: 0.9330 - val_loss: 0.8961 - val_acc: 0.7779\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 410s 4s/step - loss: 0.1543 - acc: 0.9545 - val_loss: 0.7880 - val_acc: 0.8022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f94a8391ef0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_model.fit_generator(train_generator, steps_per_epoch=100, epochs=5, validation_data=valid_generator, \n",
    "                          validation_steps=valid_full_path_steps, max_queue_size=30, workers=3, \n",
    "                          use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ce97f9afc4479aa86a7504b964fc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 108s 2s/step\n",
      "48/48 [==============================] - 109s 2s/step\n",
      "48/48 [==============================] - 109s 2s/step\n",
      "48/48 [==============================] - 109s 2s/step\n",
      "48/48 [==============================] - 109s 2s/step\n",
      "48/48 [==============================] - 109s 2s/step\n",
      "48/48 [==============================] - 109s 2s/step\n",
      "48/48 [==============================] - 109s 2s/step\n",
      "48/48 [==============================] - 109s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2366,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "for i in tqdm_notebook(range(10)):\n",
    "    test_val_gen = get_train_generator(X_test, y_test, batch_size=BATCH_SIZE, circle=False, shuffle_data=False,\n",
    "                                       shuffle_frame=True)\n",
    "    prediction = super_model.predict_generator(test_val_gen, steps=valid_full_path_steps, verbose=1)\n",
    "    preds.append(prediction)\n",
    "    \n",
    "final_preds = np.zeros_like(preds[0])\n",
    "for prd in preds:\n",
    "    final_preds += prd\n",
    "final_preds /= len(preds)\n",
    "total_prediction = np.argmax(final_preds, axis=1)\n",
    "total_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8672865595942519"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(total_prediction, y_test.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f450ecb526413ca5fa3893607272db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 171s 2s/step\n",
      "75/75 [==============================] - 171s 2s/step\n",
      "75/75 [==============================] - 171s 2s/step\n",
      "75/75 [==============================] - 171s 2s/step\n",
      "75/75 [==============================] - 171s 2s/step\n",
      "75/75 [==============================] - 171s 2s/step\n",
      "75/75 [==============================] - 171s 2s/step\n",
      "75/75 [==============================] - 171s 2s/step\n",
      "75/75 [==============================] - 171s 2s/step\n",
      "75/75 [==============================] - 171s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3729,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_names = os.listdir('data/test_converted/imgs/')\n",
    "test_full_pass_steps = np.ceil(len(vid_names) / BATCH_SIZE)\n",
    "preds = []\n",
    "for i in tqdm_notebook(range(10)):\n",
    "    test_eval_gen = get_eval_generator(vid_names, batch_size=BATCH_SIZE)\n",
    "    prediction = super_model.predict_generator(test_eval_gen, steps=test_full_pass_steps, max_queue_size=30, verbose=1)\n",
    "    preds.append(prediction)\n",
    "    \n",
    "final_preds = np.zeros_like(preds[0])\n",
    "for prd in preds:\n",
    "    final_preds += prd\n",
    "final_preds /= len(preds)\n",
    "total_prediction = np.argmax(final_preds, axis=1)\n",
    "total_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>classnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0690.avi</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2654.avi</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3132.avi</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0931.avi</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3689.avi</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename  classnum\n",
       "0  0690.avi        13\n",
       "1  2654.avi        35\n",
       "2  3132.avi        75\n",
       "3  0931.avi        92\n",
       "4  3689.avi        25"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({'filename':['{}.avi'.format(name) for name in vid_names], 'classnum':total_prediction})\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('rgb_bid_lstm512_with_avg_pretty_tuned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rgb_bid_lstm512_with_avg_pretty_tuned.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
