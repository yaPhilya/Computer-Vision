{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as L\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**map index to label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>classnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.avi</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.avi</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.avi</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.avi</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.avi</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename  classnum\n",
       "0  0000.avi        56\n",
       "1  0001.avi        51\n",
       "2  0002.avi        64\n",
       "3  0003.avi        23\n",
       "4  0004.avi        41"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/train_gt.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = []\n",
    "file_name = []\n",
    "for row in data.iterrows():\n",
    "    name, label = row[1]['filename'], row[1]['classnum']\n",
    "    idx = name.split('.')[0]\n",
    "    file_name.append(idx)\n",
    "    class_num.append(int(label))\n",
    "class_num = np.array(class_num)\n",
    "file_name = np.array(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([56, 51, 64, 23, 41, 69, 11, 34, 47, 16]),\n",
       " array(['0000', '0001', '0002', '0003', '0004', '0005', '0006', '0007',\n",
       "        '0008', '0009'], dtype='<U4'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num[:10], file_name[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num.min(), class_num.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.cudnn_recurrent import CuDNNLSTM\n",
    "from keras.layers.pooling import GlobalAveragePooling1D, GlobalAveragePooling2D\n",
    "from keras.layers.merge import Average\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import InputLayer, Input\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7097,),\n",
       " (7097,),\n",
       " array(['1717', '5174', '2784', '2820', '1936'], dtype='<U4'),\n",
       " array([84, 49, 30,  6,  0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(file_name, class_num)\n",
    "X_train.shape, y_train.shape, X_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, class_num.max() + 1)\n",
    "y_test = np_utils.to_categorical(y_test, class_num.max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7097, 101)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1776, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_frames = []\n",
    "for name in os.listdir('data/train_converted/imgs/'):\n",
    "    num_frames.append(len(os.listdir('data/train_converted/imgs/' + name)))\n",
    "np.max(num_frames), np.min(num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 240, 320, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((4, 30, 240, 320, 3))\n",
    "a[1:3, [1,2,3,4]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7097,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAMES = 10\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SHAPE = (240, 320, 3)\n",
    "TENSOR_SHAPE = (NUM_FRAMES, ) + IMAGE_SHAPE\n",
    "TRAIN_IMGS_PATH = 'data/train_converted/imgs/'\n",
    "TRAIN_FLOW_PATH = 'data/train_converted/flow/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_generator(data, label, batch_size=32, circle=True, shuffle_data=True, shuffle_frame=True):\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle_data:\n",
    "            indices = np.random.permutation(indices)\n",
    "        for start in range(0, len(data), batch_size):\n",
    "            batch_idx = indices[start : start + batch_size]\n",
    "            y_batch = label[batch_idx]\n",
    "            X_batch = np.zeros((y_batch.shape[0],) + TENSOR_SHAPE)\n",
    "            for i, name in enumerate(data[batch_idx]):\n",
    "                for k in range(NUM_FRAMES):\n",
    "                    if not shuffle_frame:\n",
    "                        start_frame = 0\n",
    "                    else:\n",
    "                        start_frame = np.random.randint(int(0.5 * len(os.listdir(TRAIN_IMGS_PATH + name))))\n",
    "                    img = cv2.imread(TRAIN_IMGS_PATH + '{}/{}.jpg'.format(name, k + start_frame))\n",
    "                    X_batch[i, k] = preprocess_input(img)\n",
    "            yield X_batch, y_batch\n",
    "        if not circle:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_flow_generator(data, label, batch_size=32, circle=True, shuffle_data=True, shuffle_frame=True):\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle_data:\n",
    "            indices = np.random.permutation(indices)\n",
    "        for start in range(0, len(data), batch_size):\n",
    "            batch_idx = indices[start : start + batch_size]\n",
    "            y_batch = label[batch_idx]\n",
    "            X_batch = np.zeros((y_batch.shape[0],) + TENSOR_SHAPE)\n",
    "            for i, name in enumerate(data[batch_idx]):\n",
    "                for k in range(NUM_FRAMES):\n",
    "                    if not shuffle_frame:\n",
    "                        start = 1\n",
    "                    else:\n",
    "                        start = np.random.randint(1, int(0.5 * len(os.listdir(TRAIN_FLOW_PATH + name))))\n",
    "                    img = cv2.imread(TRAIN_FLOW_PATH + '{}/{}.jpg'.format(name, k + start))\n",
    "                    X_batch[i, k] = preprocess_input(img)\n",
    "            yield X_batch, y_batch\n",
    "        if not circle:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_generator(names, batch_size=32):\n",
    "    for start in range(0, len(names), batch_size):\n",
    "        sub_names = names[start : start + batch_size]\n",
    "        X_batch = np.zeros((len(sub_names),) + TENSOR_SHAPE)\n",
    "        for i, name in enumerate(sub_names):\n",
    "            for k in range(NUM_FRAMES):\n",
    "                start_frame = np.random.randint(int(0.5 * len(os.listdir('data/test_converted/imgs/' + name))))\n",
    "                img = cv2.imread('data/test_converted/imgs/{}/{}.jpg'.format(name, k + start_frame))\n",
    "                X_batch[i, k] = preprocess_input(img)\n",
    "        yield X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "global MODEL\n",
    "MODEL = Xception(include_top=False, weights='imagenet')\n",
    "global GRAPH\n",
    "GRAPH = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rgb_model(lstm_size):\n",
    "    base_model = TimeDistributed(MODEL)\n",
    "    base_model(Input(shape=TENSOR_SHAPE))\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = TimeDistributed(GlobalAveragePooling2D())(x)\n",
    "    x = CuDNNLSTM(lstm_size)(x)\n",
    "    predictions = Dense(101, activation='softmax')(x)\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layer.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    parallel_model = multi_gpu_model(model)\n",
    "    parallel_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return parallel_model, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_model, model = get_rgb_model(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = get_train_generator(X_train, y_train, batch_size=BATCH_SIZE, circle=True, shuffle_data=True, shuffle_frame=True)\n",
    "valid_generator = get_train_generator(X_test, y_test, batch_size=BATCH_SIZE, circle=True, shuffle_data=False, shuffle_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2366,), (2366, 101))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_full_path_steps = np.ceil(len(X_test) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ya-philya/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 243s 2s/step - loss: 3.4939 - acc: 0.2591 - val_loss: 2.9201 - val_acc: 0.3079\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 231s 2s/step - loss: 0.8737 - acc: 0.7909 - val_loss: 1.6641 - val_acc: 0.5621\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.5894 - acc: 0.8494 - val_loss: 1.5734 - val_acc: 0.5940\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 219s 2s/step - loss: 0.4970 - acc: 0.8759 - val_loss: 1.4500 - val_acc: 0.6090\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 216s 2s/step - loss: 0.4823 - acc: 0.8744 - val_loss: 1.2190 - val_acc: 0.6672\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 230s 2s/step - loss: 0.4158 - acc: 0.8866 - val_loss: 1.1834 - val_acc: 0.6850\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 218s 2s/step - loss: 0.3190 - acc: 0.9134 - val_loss: 1.1699 - val_acc: 0.6782\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 219s 2s/step - loss: 0.2537 - acc: 0.9303 - val_loss: 0.9078 - val_acc: 0.7597\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 231s 2s/step - loss: 0.2293 - acc: 0.9387 - val_loss: 0.9447 - val_acc: 0.7413\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 221s 2s/step - loss: 0.2323 - acc: 0.9344 - val_loss: 1.0260 - val_acc: 0.7441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f91d1a2bcc0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_model.fit_generator(train_generator, steps_per_epoch=100, epochs=10, validation_data=valid_generator, \n",
    "                          validation_steps=valid_full_path_steps, max_queue_size=30, workers=3, \n",
    "                          use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "100/100 [==============================] - 239s 2s/step - loss: 0.2194 - acc: 0.9397 - val_loss: 0.9460 - val_acc: 0.7454\n",
      "Epoch 2/4\n",
      "100/100 [==============================] - 229s 2s/step - loss: 0.2146 - acc: 0.9422 - val_loss: 0.8309 - val_acc: 0.7690\n",
      "Epoch 3/4\n",
      "100/100 [==============================] - 228s 2s/step - loss: 0.1662 - acc: 0.9528 - val_loss: 0.8879 - val_acc: 0.7587\n",
      "Epoch 4/4\n",
      "100/100 [==============================] - 230s 2s/step - loss: 0.1782 - acc: 0.9528 - val_loss: 0.9305 - val_acc: 0.7568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f91d1a2b5f8>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_model.fit_generator(train_generator, steps_per_epoch=100, epochs=4, validation_data=valid_generator, \n",
    "                          validation_steps=valid_full_path_steps, max_queue_size=30, workers=3, \n",
    "                          use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687f1269fd2f4261a6dac85e20b7e63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for i in tqdm_notebook(range(10)):\n",
    "    test_val_gen = get_train_generator(X_test, y_test, batch_size=BATCH_SIZE, circle=False, shuffle_data=False,\n",
    "                                       shuffle_frame=True)\n",
    "    prediction = super_model.predict_generator(test_val_gen, steps=valid_full_path_steps)\n",
    "    preds.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2366,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds = np.zeros_like(preds[0])\n",
    "for prd in preds:\n",
    "    final_preds += prd\n",
    "final_preds /= len(preds)\n",
    "total_prediction = np.argmax(final_preds, axis=1)\n",
    "total_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8250211327134404"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(total_prediction, y_test.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7688e1c40f45f3af77c8e0872b3fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 171s 1s/step\n",
      "117/117 [==============================] - 171s 1s/step\n",
      "117/117 [==============================] - 171s 1s/step\n",
      "117/117 [==============================] - 171s 1s/step\n",
      "117/117 [==============================] - 171s 1s/step\n",
      "117/117 [==============================] - 171s 1s/step\n",
      "117/117 [==============================] - 171s 1s/step\n",
      "117/117 [==============================] - 171s 1s/step\n",
      "117/117 [==============================] - 171s 1s/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3729,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_names = os.listdir('data/test_converted/imgs/')\n",
    "test_full_pass_steps = np.ceil(len(vid_names) / BATCH_SIZE)\n",
    "preds = []\n",
    "for i in tqdm_notebook(range(10)):\n",
    "    test_eval_gen = get_eval_generator(vid_names, batch_size=BATCH_SIZE)\n",
    "    prediction = super_model.predict_generator(test_eval_gen, steps=test_full_pass_steps, max_queue_size=30, verbose=1)\n",
    "    preds.append(prediction)\n",
    "    \n",
    "final_preds = np.zeros_like(preds[0])\n",
    "for prd in preds:\n",
    "    final_preds += prd\n",
    "final_preds /= len(preds)\n",
    "total_prediction = np.argmax(final_preds, axis=1)\n",
    "total_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>classnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0690.avi</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2654.avi</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3132.avi</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0931.avi</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3689.avi</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filenames  classnum\n",
       "0  0690.avi        13\n",
       "1  2654.avi        35\n",
       "2  3132.avi        75\n",
       "3  0931.avi        78\n",
       "4  3689.avi        25"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({'filenames':['{}.avi'.format(name) for name in vid_names], 'classnum':total_prediction})\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('rgb_lstm512_pretty_tuned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rgb_lstm512_pretty_tuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_super_model, flow_model = get_rgb_model(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = get_train_flow_generator(X_train, y_train, batch_size=BATCH_SIZE, circle=True, shuffle_data=True, shuffle_frame=True)\n",
    "valid_generator = get_train_flow_generator(X_test, y_test, batch_size=BATCH_SIZE, circle=True, shuffle_data=False, shuffle_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ya-philya/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 264s 3s/step - loss: 2.3844 - acc: 0.5019 - val_loss: 4.9726 - val_acc: 0.0465\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 224s 2s/step - loss: 1.5536 - acc: 0.6950 - val_loss: 4.8223 - val_acc: 0.0617\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.3149 - acc: 0.7469 - val_loss: 4.5843 - val_acc: 0.0828\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 219s 2s/step - loss: 1.2756 - acc: 0.7531 - val_loss: 4.3778 - val_acc: 0.1090\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.1783 - acc: 0.7666 - val_loss: 4.3020 - val_acc: 0.1098\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.0905 - acc: 0.7866 - val_loss: 4.5021 - val_acc: 0.1216\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 225s 2s/step - loss: 1.0361 - acc: 0.7950 - val_loss: 4.1698 - val_acc: 0.1191\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 226s 2s/step - loss: 0.9684 - acc: 0.8113 - val_loss: 4.1344 - val_acc: 0.1047\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 219s 2s/step - loss: 0.9538 - acc: 0.8109 - val_loss: 3.9631 - val_acc: 0.1613\n"
     ]
    }
   ],
   "source": [
    "history = flow_super_model.fit_generator(train_generator, steps_per_epoch=100, epochs=10, validation_data=valid_generator, \n",
    "                          validation_steps=valid_full_path_steps, max_queue_size=60, workers=6, \n",
    "                          use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 341s 2s/step - loss: 1.4077 - acc: 0.6923 - val_loss: 3.7858 - val_acc: 0.1723\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 342s 2s/step - loss: 1.1732 - acc: 0.7413 - val_loss: 3.5515 - val_acc: 0.2078\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 339s 2s/step - loss: 1.1866 - acc: 0.7334 - val_loss: 3.6405 - val_acc: 0.1901\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 342s 2s/step - loss: 1.2532 - acc: 0.7192 - val_loss: 3.7363 - val_acc: 0.1900\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 333s 2s/step - loss: 1.1597 - acc: 0.7334 - val_loss: 3.2765 - val_acc: 0.2454\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 343s 2s/step - loss: 1.1419 - acc: 0.7408 - val_loss: 3.4091 - val_acc: 0.2384\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 330s 2s/step - loss: 1.0719 - acc: 0.7544 - val_loss: 3.3819 - val_acc: 0.2365\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 344s 2s/step - loss: 1.0084 - acc: 0.7637 - val_loss: 3.1475 - val_acc: 0.2703\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 346s 2s/step - loss: 0.9749 - acc: 0.7720 - val_loss: 3.2454 - val_acc: 0.2549\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 322s 2s/step - loss: 0.9518 - acc: 0.7752 - val_loss: 3.1673 - val_acc: 0.2542\n"
     ]
    }
   ],
   "source": [
    "history = flow_super_model.fit_generator(train_generator, steps_per_epoch=200, epochs=10, validation_data=valid_generator, \n",
    "                          validation_steps=valid_full_path_steps, max_queue_size=30, workers=3, \n",
    "                          use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_1 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_1 False\n",
      "15 add_1 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_2 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_2 False\n",
      "25 add_2 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_3 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_3 False\n",
      "35 add_3 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_4 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_5 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_6 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_7 False\n",
      "76 block9_sepconv1_act False\n",
      "77 block9_sepconv1 False\n",
      "78 block9_sepconv1_bn False\n",
      "79 block9_sepconv2_act False\n",
      "80 block9_sepconv2 False\n",
      "81 block9_sepconv2_bn False\n",
      "82 block9_sepconv3_act False\n",
      "83 block9_sepconv3 False\n",
      "84 block9_sepconv3_bn False\n",
      "85 add_8 False\n",
      "86 block10_sepconv1_act False\n",
      "87 block10_sepconv1 False\n",
      "88 block10_sepconv1_bn False\n",
      "89 block10_sepconv2_act False\n",
      "90 block10_sepconv2 False\n",
      "91 block10_sepconv2_bn False\n",
      "92 block10_sepconv3_act False\n",
      "93 block10_sepconv3 False\n",
      "94 block10_sepconv3_bn False\n",
      "95 add_9 False\n",
      "96 block11_sepconv1_act False\n",
      "97 block11_sepconv1 False\n",
      "98 block11_sepconv1_bn False\n",
      "99 block11_sepconv2_act False\n",
      "100 block11_sepconv2 False\n",
      "101 block11_sepconv2_bn False\n",
      "102 block11_sepconv3_act False\n",
      "103 block11_sepconv3 False\n",
      "104 block11_sepconv3_bn False\n",
      "105 add_10 False\n",
      "106 block12_sepconv1_act False\n",
      "107 block12_sepconv1 False\n",
      "108 block12_sepconv1_bn False\n",
      "109 block12_sepconv2_act False\n",
      "110 block12_sepconv2 False\n",
      "111 block12_sepconv2_bn False\n",
      "112 block12_sepconv3_act False\n",
      "113 block12_sepconv3 False\n",
      "114 block12_sepconv3_bn False\n",
      "115 add_11 False\n",
      "116 block13_sepconv1_act False\n",
      "117 block13_sepconv1 False\n",
      "118 block13_sepconv1_bn False\n",
      "119 block13_sepconv2_act False\n",
      "120 block13_sepconv2 False\n",
      "121 block13_sepconv2_bn False\n",
      "122 conv2d_4 False\n",
      "123 block13_pool False\n",
      "124 batch_normalization_4 False\n",
      "125 add_12 False\n",
      "126 block14_sepconv1 False\n",
      "127 block14_sepconv1_bn False\n",
      "128 block14_sepconv1_act False\n",
      "129 block14_sepconv2 False\n",
      "130 block14_sepconv2_bn False\n",
      "131 block14_sepconv2_act False\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(flow_model.layers[1].layer.layers):\n",
    "    print(i, l.name, l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activ_model(model):\n",
    "    for l in model.layers[1].layer.layers[126:]:\n",
    "        l.trainable = True\n",
    "\n",
    "def disactiv_model(model):\n",
    "    for l in model.layers[1].layer.layers[126:]:\n",
    "        l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "activ_model(flow_model)\n",
    "flow_super_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ya-philya/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 346s 2s/step - loss: 4.5091 - acc: 0.0584 - val_loss: 4.8967 - val_acc: 0.0051\n",
      "Epoch 2/3\n",
      "200/200 [==============================] - 344s 2s/step - loss: 4.3244 - acc: 0.0666 - val_loss: 4.6854 - val_acc: 0.0228\n",
      "Epoch 3/3\n",
      "200/200 [==============================] - 345s 2s/step - loss: 4.0863 - acc: 0.0894 - val_loss: 4.7102 - val_acc: 0.0406\n"
     ]
    }
   ],
   "source": [
    "history = flow_super_model.fit_generator(train_generator, steps_per_epoch=200, epochs=3, validation_data=valid_generator, \n",
    "                          validation_steps=valid_full_path_steps, max_queue_size=30, workers=3, \n",
    "                          use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "block1_conv1 False\n",
      "block1_conv1_bn False\n",
      "block1_conv1_act False\n",
      "block1_conv2 False\n",
      "block1_conv2_bn False\n",
      "block1_conv2_act False\n",
      "block2_sepconv1 False\n",
      "block2_sepconv1_bn False\n",
      "block2_sepconv2_act False\n",
      "block2_sepconv2 False\n",
      "block2_sepconv2_bn False\n",
      "conv2d_1 False\n",
      "block2_pool False\n",
      "batch_normalization_1 False\n",
      "add_1 False\n",
      "block3_sepconv1_act False\n",
      "block3_sepconv1 False\n",
      "block3_sepconv1_bn False\n",
      "block3_sepconv2_act False\n",
      "block3_sepconv2 False\n",
      "block3_sepconv2_bn False\n",
      "conv2d_2 False\n",
      "block3_pool False\n",
      "batch_normalization_2 False\n",
      "add_2 False\n",
      "block4_sepconv1_act False\n",
      "block4_sepconv1 False\n",
      "block4_sepconv1_bn False\n",
      "block4_sepconv2_act False\n",
      "block4_sepconv2 False\n",
      "block4_sepconv2_bn False\n",
      "conv2d_3 False\n",
      "block4_pool False\n",
      "batch_normalization_3 False\n",
      "add_3 False\n",
      "block5_sepconv1_act False\n",
      "block5_sepconv1 False\n",
      "block5_sepconv1_bn False\n",
      "block5_sepconv2_act False\n",
      "block5_sepconv2 False\n",
      "block5_sepconv2_bn False\n",
      "block5_sepconv3_act False\n",
      "block5_sepconv3 False\n",
      "block5_sepconv3_bn False\n",
      "add_4 False\n",
      "block6_sepconv1_act False\n",
      "block6_sepconv1 False\n",
      "block6_sepconv1_bn False\n",
      "block6_sepconv2_act False\n",
      "block6_sepconv2 False\n",
      "block6_sepconv2_bn False\n",
      "block6_sepconv3_act False\n",
      "block6_sepconv3 False\n",
      "block6_sepconv3_bn False\n",
      "add_5 False\n",
      "block7_sepconv1_act False\n",
      "block7_sepconv1 False\n",
      "block7_sepconv1_bn False\n",
      "block7_sepconv2_act False\n",
      "block7_sepconv2 False\n",
      "block7_sepconv2_bn False\n",
      "block7_sepconv3_act False\n",
      "block7_sepconv3 False\n",
      "block7_sepconv3_bn False\n",
      "add_6 False\n",
      "block8_sepconv1_act False\n",
      "block8_sepconv1 False\n",
      "block8_sepconv1_bn False\n",
      "block8_sepconv2_act False\n",
      "block8_sepconv2 False\n",
      "block8_sepconv2_bn False\n",
      "block8_sepconv3_act False\n",
      "block8_sepconv3 False\n",
      "block8_sepconv3_bn False\n",
      "add_7 False\n",
      "block9_sepconv1_act False\n",
      "block9_sepconv1 False\n",
      "block9_sepconv1_bn False\n",
      "block9_sepconv2_act False\n",
      "block9_sepconv2 False\n",
      "block9_sepconv2_bn False\n",
      "block9_sepconv3_act False\n",
      "block9_sepconv3 False\n",
      "block9_sepconv3_bn False\n",
      "add_8 False\n",
      "block10_sepconv1_act False\n",
      "block10_sepconv1 False\n",
      "block10_sepconv1_bn False\n",
      "block10_sepconv2_act False\n",
      "block10_sepconv2 False\n",
      "block10_sepconv2_bn False\n",
      "block10_sepconv3_act False\n",
      "block10_sepconv3 False\n",
      "block10_sepconv3_bn False\n",
      "add_9 False\n",
      "block11_sepconv1_act False\n",
      "block11_sepconv1 False\n",
      "block11_sepconv1_bn False\n",
      "block11_sepconv2_act False\n",
      "block11_sepconv2 False\n",
      "block11_sepconv2_bn False\n",
      "block11_sepconv3_act False\n",
      "block11_sepconv3 False\n",
      "block11_sepconv3_bn False\n",
      "add_10 False\n",
      "block12_sepconv1_act False\n",
      "block12_sepconv1 False\n",
      "block12_sepconv1_bn False\n",
      "block12_sepconv2_act False\n",
      "block12_sepconv2 False\n",
      "block12_sepconv2_bn False\n",
      "block12_sepconv3_act False\n",
      "block12_sepconv3 False\n",
      "block12_sepconv3_bn False\n",
      "add_11 False\n",
      "block13_sepconv1_act False\n",
      "block13_sepconv1 False\n",
      "block13_sepconv1_bn False\n",
      "block13_sepconv2_act False\n",
      "block13_sepconv2 False\n",
      "block13_sepconv2_bn False\n",
      "conv2d_4 False\n",
      "block13_pool False\n",
      "batch_normalization_4 False\n",
      "add_12 False\n",
      "block14_sepconv1 True\n",
      "block14_sepconv1_bn True\n",
      "block14_sepconv1_act True\n",
      "block14_sepconv2 True\n",
      "block14_sepconv2_bn True\n",
      "block14_sepconv2_act True\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers[1].layer.layers:\n",
    "    print(l.name, l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df69abfa09724117b127b740fbb19a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3729), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {}\n",
    "\n",
    "for name in tqdm_notebook(os.listdir('data/test_converted/imgs/')):\n",
    "    X_batch = np.zeros((1, 10, 240, 320, 3))\n",
    "    for k in range(10):\n",
    "        img = cv2.imread('data/test_converted/imgs/{}/{}.jpg'.format(name, k))\n",
    "        X_batch[0, k] = preprocess_input(img)\n",
    "    prediction = model.predict_on_batch(X_batch)[0]\n",
    "    preds[name] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>classnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0690.avi</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2654.avi</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3132.avi</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0931.avi</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3689.avi</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename  classnum\n",
       "0  0690.avi        13\n",
       "1  2654.avi        35\n",
       "2  3132.avi        48\n",
       "3  0931.avi        15\n",
       "4  3689.avi        25"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fn = []\n",
    "test_class = []\n",
    "for fn, cls in preds.items():\n",
    "    test_fn += [fn+'.avi']\n",
    "    test_class += [cls.argmax()]\n",
    "sub = pd.DataFrame({'filename':test_fn, 'classnum':test_class})\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('rgb_lstm_model1_sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rgb_lstm_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
