{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание: Визуализация и применение оптического потока\n",
    "В данном задании Вы попрактикуетесь в применении методов вычисления оптического потока и его визуализации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 0: Подготовка\n",
    "Для работы с методами оптического потока и удобной визузализации нам будут необходимы следующие библиотеки:\n",
    "- opencv\n",
    "- pyflow (https://github.com/pathak22/pyflow)\n",
    "- imageio\n",
    "- matplotlib\n",
    "- scikit-image\n",
    "- PIL\n",
    "\n",
    "Убедитесь, что они у вас установлены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread, imshow, imsave\n",
    "import IPython\n",
    "import cv2\n",
    "from pyflow import pyflow\n",
    "import matplotlib.pyplot as plt\n",
    "from math import gcd\n",
    "import imageio\n",
    "from PIL import Image, ImageSequence\n",
    "import warnings\n",
    "\n",
    "\n",
    "def gifread(gifname):\n",
    "    im = Image.open(gifname)\n",
    "    duration = im.info['duration']/1000.\n",
    "    frames = [(np.array(frame.copy().convert('RGB'))/255.).astype(np.float64).copy()\n",
    "              for frame in ImageSequence.Iterator(im)]\n",
    "    return frames, duration\n",
    "\n",
    "\n",
    "def gifshow(gifname):\n",
    "    with open(gifname, 'rb') as f:\n",
    "        display(IPython.display.Image(data=f.read(), format='png'))\n",
    "\n",
    "\n",
    "def gifsave(gifname, images, duration=2):\n",
    "    images = [imageio.core.util.Image(img) for img in images]\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        imageio.mimsave(gifname, images, duration=duration)\n",
    "\n",
    "\n",
    "def seqmerge(imgs1, imgs2, mode='horizontal'):\n",
    "    len_gcd = gcd(len(imgs1), len(imgs2))\n",
    "    imgs1_repeat = len(imgs2)//len_gcd\n",
    "    imgs2_repeat = len(imgs1)//len_gcd\n",
    "    imgs1 = np.repeat(imgs1, imgs1_repeat, axis=0)\n",
    "    imgs2 = np.repeat(imgs2, imgs2_repeat, axis=0)\n",
    "    imgs = np.concatenate(\n",
    "        (imgs1, imgs2), axis=2 if mode.startswith('hor') else 1)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализировать результат будет удобно в виде GIF-анимаций, для чего вы можете использовать функции `gifread`, `gifsave`, `gifshow` и `seqmerge`, пример использования ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, duration = gifread('data/cat.gif')\n",
    "flipped_frames = [f[::-1, ...] for f in frames[::-1]]\n",
    "res_frames = seqmerge(frames, flipped_frames, mode='vertical')\n",
    "gifsave('double_cat.gif', res_frames, duration=duration)\n",
    "gifshow('double_cat.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Что такое оптический поток\n",
    "\n",
    "Оптический поток – это мера видимого движения объектов на видеопоследовательности относительно плоскости изображения. На практике оптический поток разделяется на 2 типа: __плотный__ (dense) и __разреженный__ (sparse). С помощью плотного оптического потока производится оценка смещения каждого пикселя изображения, в том время как с помощью разреженного оценивают только некоторые, заранее определенные точки, что значительно экономит ресурсы по сравнению с первым методом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Плотный оптический поток и его визуализация\n",
    "<img src=\"imgs/dof.jpg\" width=350 align=\"right\">\n",
    "Для расчета плотного оптического потока применим быстрый метод расчета по пирамиде изображений (https://people.csail.mit.edu/celiu/OpticalFlow/). Для визуализации полученного оптического потока можно применить следующий метод: направлению вектора будет соответствовать Hue в цветовой модели HSV, а абсолютному значению – Value\n",
    "\n",
    "__Задание 1.__ Сделайте визуализацию оптического потока по HSV. Подберите оптимальные параметры для вычисления оптического потока между двумя кадрами в коде ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = np.array(Image.open('data/car1.jpg'))\n",
    "im2 = np.array(Image.open('data/car2.jpg'))\n",
    "im1 = im1.astype(float) / 255.\n",
    "im2 = im2.astype(float) / 255.\n",
    "\n",
    "# Parameters to tune\n",
    "alpha = 0.012\n",
    "ratio = 0.75\n",
    "minWidth = 20\n",
    "nOuterFPIterations = 7\n",
    "nInnerFPIterations = 1\n",
    "nSORIterations = 30\n",
    "colType = 0\n",
    "\n",
    "u, v, im2W = pyflow.coarse2fine_flow(\n",
    "    im1, im2, alpha, ratio, minWidth, nOuterFPIterations, nInnerFPIterations,\n",
    "    nSORIterations, colType)\n",
    "flow = np.concatenate((u[..., None], v[..., None]), axis=2)\n",
    "\n",
    "# Your code here\n",
    "\n",
    "imshow(rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Плотный оптический поток имеет несколько применений. Одно из них – интерполирование видеопоследовательностей для увеличения частоты кадров и плавности движения. С помощью вычисленного на предыдущем шаге потоке попробуйте сгенерировать кадр между двумя настоящими.\n",
    "\n",
    "__Задание 2.__ Реализуйте функцию `warp_flow`, выполняющую интерполяцию кадров по потоку и первому изображению. *Подсказка:* Используйте функцию `cv2.remap`, для неё пиксели должны быть в формате `np.float32`. Не забудьте в конце привести значения пикселей к [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_flow(img, flow):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im3 = warp_flow(im1, flow.astype(np.float32).copy())\n",
    "seq = seqmerge([im1, im1, im2], [im1, im3, im2])\n",
    "gifsave('warped.gif', seq, duration=1.5)\n",
    "gifshow('warped.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем применить данный метод для видео. Заметно ли увеличение плавности?\n",
    "\n",
    "__Задание 3.__ Реализуйте функцию `interp_frames`, вычисляющую плотный оптический поток между соседними кадрами и интерполирующую кадр между ними. Примените функцию к gifs/traffic.gif и визуализируйте результат в виде анимации, сравните с оригиналом. *Подсказка:* Не забудьте уменьшить параметр `duration` для итоговой анимации в 2 раза."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_frames(frames):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Разреженный оптический поток\n",
    "<img src=\"imgs/opticalflow_lk.jpg\" width=350 align=\"right\">\n",
    "\n",
    "Методы разреженного оптического потока чаще всего работают медленней, чем плотного, из расчета на одну отслеживаемую точку, однако отличаются большей надежностью отслеживания необходимых точек и потому применяются в задачах трекинга объектов.\n",
    "\n",
    "Попробуем рассчитать поток по методу Лукаса-Канаде (https://en.wikipedia.org/wiki/Lucas–Kanade_method). Для этого сначала необходимо задать интересующие нас точки, найдем их с помощью `cv2.goodFeaturesToTrack`. Затем применим метод к каждой паре соседних кадров и получим на выходе положения интересующих точек на каждом кадре последовательности.\n",
    "\n",
    "__Задание 4.__ Напишите функцию визуализации треков получаемых точек `sparseflow_visualise`. На каждом кадре функция должна продолжать линии разных цветов согласно точкам, чтобы получилось изображение, похожее на пример справа. Примените функцию вычисления разреженного оптического потока `compute_sparse_flow` к gifs/traffic.gif. Визуализируйте результат в виде анимации. Подберите оптимальные параметры для предотвращения потери ключевых точек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sparse_flow(images):\n",
    "    def to_uint8(images):\n",
    "        if images[0].dtype != np.uint8:\n",
    "            images = [(img*255).astype(np.uint8).copy() for img in images]\n",
    "        return images\n",
    "    res = []\n",
    "    images = to_uint8(images)\n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params = dict(maxCorners=30,\n",
    "                          qualityLevel=0.4,\n",
    "                          minDistance=7,\n",
    "                          blockSize=7)\n",
    "    # Parameters for Lucas-Kanade optical flow\n",
    "    lk_params = dict(winSize=(7, 5),\n",
    "                     maxLevel=40,\n",
    "                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 40, 0.1))\n",
    "\n",
    "    prev_gray = cv2.cvtColor(images[0], cv2.COLOR_RGB2GRAY)\n",
    "    prev_features = cv2.goodFeaturesToTrack(\n",
    "        prev_gray, mask=None, **feature_params).reshape(-1, 2)\n",
    "    res.append(prev_features)\n",
    "    features_len = len(prev_features)\n",
    "    feature_mask = np.ones(features_len, dtype=np.bool)\n",
    "    for image in images[1:]:\n",
    "        curr_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        curr_features, curr_feature_mask, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray,\n",
    "                                          prev_features.reshape(-1, 1, 2).copy(), None, **lk_params)\n",
    "        curr_feature_mask = curr_feature_mask.flatten()\n",
    "        prev_features = curr_features[curr_feature_mask == 1, ...].reshape(-1, 2).copy()\n",
    "        feature_mask[feature_mask] = (curr_feature_mask == 1)\n",
    "        features_to_add = np.ones((features_len, 2)) * np.inf\n",
    "        features_to_add[feature_mask, :] = prev_features\n",
    "        res.append(features_to_add)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparseflow_visualise(images, points):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы можете заметить, как трекинг практически всегда срывается при значительном изменении окружения точки (в данном случае, изменение освещения корпусов машин, когда они выезжают на солнце). Можно сделать вывод, что для качественного вычисления оптического потока необходимо более глубокое понимание сцены, чем простое сравнение областей, именно поэтому в данный момент наиболее перспективными методами решения данной задачи являются методы с применением нейросетей. Один из самых известных примеров – FlowNet, подробней о котором можно прочесть здесь: https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Dosovitskiy_FlowNet_Learning_Optical_ICCV_2015_paper.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
